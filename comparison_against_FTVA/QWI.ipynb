{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import copy\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02232142, 0.10229283, 0.87538575],\n",
       "       [0.03426605, 0.17175704, 0.79397691],\n",
       "       [0.52324756, 0.45523298, 0.02151947]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_0_matrix=np.array([[0.02232142,0.10229283,0.87538575],\n",
    "                   [0.03426605,0.17175704,0.79397691],\n",
    "                   [0.52324756,0.45523298,0.02151947]])\n",
    "\n",
    "P_0_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14874601, 0.30435809, 0.54689589],\n",
       "       [0.56845754, 0.41117331, 0.02036915],\n",
       "       [0.2526557 , 0.27310439, 0.4742399 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_1_matrix=np.array([[0.14874601,0.30435809,0.54689589],\n",
    "                   [0.56845754,0.41117331,0.02036915],\n",
    "                   [0.25265570,0.27310439,0.4742399]])\n",
    "P_1_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space=[0,1]\n",
    "state_space=[0,1,2]\n",
    "reward_matrix=[[0,0.37401552],[0,0.11740814],[0,0.07866135]]\n",
    "epsilon=0.1\n",
    "# N=250\n",
    "# M=100\n",
    "# epsilon=0.1\n",
    "# subsidy=0\n",
    "# arm_indexes=[i for i in range(N)]\n",
    "# gamma=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state,state_space,action,P_0_matrix,P_1_matrix,reward_matrix):\n",
    "  new_state=state\n",
    "  if(action==1):\n",
    "    new_state=np.random.choice(state_space,replace=True,p=P_1_matrix[state])\n",
    "    reward=reward_matrix[state][1]\n",
    "  else:\n",
    "    new_state=np.random.choice(state_space,replace=True,p=P_0_matrix[state])\n",
    "    reward=reward_matrix[state][0]\n",
    "  return [new_state,reward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "M=4\n",
    "epsilon=0.1\n",
    "arm_indexes=[i for i in range(N)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(Q_values,epsilon,state,arm_index):\n",
    "  decision=np.random.binomial(n=1,p=epsilon,size=1)\n",
    "  if decision==1:\n",
    "    action=random.choice([0,1])\n",
    "  else:\n",
    "    action=np.argmax(Q_values[arm_index][state])\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state=[random.choice([0,1,2]) for _ in range(N)]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=copy.deepcopy(reward_matrix)\n",
    "Q2=copy.deepcopy(reward_matrix)\n",
    "Q3=copy.deepcopy(reward_matrix)\n",
    "\n",
    "w1=0\n",
    "w2=0\n",
    "w3=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.37401552], [0, 0.11740814], [0, 0.07866135]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_overtime=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards=[]\n",
    "subsidies=[]\n",
    "action_sums=[]\n",
    "betas=[]\n",
    "alphas=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20000001):\n",
    "  action_sum=0\n",
    "  reward_sum=0\n",
    "  T=False\n",
    "  alpha=1/np.ceil(1+i/500)\n",
    "  # if(i<50000):\n",
    "  #   beta=0\n",
    "  # else:\n",
    "  if i%100==0:\n",
    "    beta=1/(1+np.ceil((i)*np.log(i)/500))\n",
    "  else:\n",
    "    beta=0\n",
    "  temp=0\n",
    "  reward=0\n",
    "  new_state=0\n",
    "  epsilon=0.1\n",
    "  whittle_index_arms=[]\n",
    "  for j in range(N):\n",
    "    if current_state[j]==0:\n",
    "      whittle_index_arms.append(w1)\n",
    "    elif current_state[j]==1:\n",
    "      whittle_index_arms.append(w2)\n",
    "    else:\n",
    "      whittle_index_arms.append(w3)\n",
    "    \n",
    "      # print(i)\n",
    "      # print('wohooo')\n",
    "\n",
    "  # indices_to_pull=get_indices_to_pull(epsilon,whittle_indexes,arm_indexes,M,current_state)\n",
    "  if random.random()>0.1:\n",
    "    indices_to_pull = sorted(range(len(whittle_index_arms)), key = lambda j: whittle_index_arms[j])[-M:]\n",
    "  else:\n",
    "    indices_to_pull=random.choices(arm_indexes,k=M)\n",
    "  # print(indices_to_pull)\n",
    "  # if(i==50000):\n",
    "  #   print(Q_values)\n",
    "  #   T=True\n",
    "  for index in arm_indexes:\n",
    "      # temp=copy.deepcopy(Q_values)\n",
    "      if index in indices_to_pull:\n",
    "        # print(i)\n",
    "        # print(alpha)\n",
    "        # print(beta)\n",
    "        # action=np.argmax(Q_values[index][current_state[index]])\n",
    "        action=1\n",
    "        # print(current_state)\n",
    "        # print(action)\n",
    "\n",
    "        action_sum+=action\n",
    "        x=step(current_state[index],state_space,action,P_0_matrix,P_1_matrix,reward_matrix)\n",
    "        new_state=x[0]\n",
    "        # print(new_state)\n",
    "        reward=x[1]\n",
    "        # print(reward)\n",
    "        Q1[current_state[index]][action]=(1-alpha)*(Q1[current_state[index]][action])+alpha*(reward+max(Q1[new_state])-(np.array(Q1).sum())/10)\n",
    "        Q2[current_state[index]][action]=(1-alpha)*(Q2[current_state[index]][action])+alpha*(reward+max(Q2[new_state])-(np.array(Q2).sum())/10)\n",
    "        Q3[current_state[index]][action]=(1-alpha)*(Q3[current_state[index]][action])+alpha*(reward+max(Q3[new_state])-(np.array(Q3).sum())/10)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # Q_values=Q_value_update(Q_values,current_state[index],new_state,action,reward,index,whittle_indexes[index][current_state[index]],alpha)\n",
    "        # print(Q_values)\n",
    "        # whittle_indexes[index][current_state[index]]+=beta*temp\n",
    "\n",
    "\n",
    "        # print(whittle_indexes)\n",
    "        # print(\"--\")\n",
    "        current_state[index]=new_state\n",
    "        reward_sum+=reward\n",
    "\n",
    "        #print(x)\n",
    "      else:\n",
    "        # print(i)\n",
    "        # print(alpha)\n",
    "        # print(beta)\n",
    "        # action=np.argmax(Q_values[index][current_state[index]])\n",
    "        action=0\n",
    "        # print(current_state)\n",
    "        # print(action)\n",
    "\n",
    "        action_sum+=action\n",
    "        x=step(current_state[index],state_space,action,P_0_matrix,P_1_matrix,reward_matrix)\n",
    "        new_state=x[0]\n",
    "        # print(new_state)\n",
    "        reward=x[1]\n",
    "        # print(reward)\n",
    "        Q1[current_state[index]][action]=(1-alpha)*(Q1[current_state[index]][action])+alpha*(reward+w1+max(Q1[new_state])-(np.array(Q1).sum())/10)\n",
    "        Q2[current_state[index]][action]=(1-alpha)*(Q2[current_state[index]][action])+alpha*(reward+w2+max(Q2[new_state])-(np.array(Q2).sum())/10)\n",
    "        Q3[current_state[index]][action]=(1-alpha)*(Q3[current_state[index]][action])+alpha*(reward+w3+max(Q3[new_state])-(np.array(Q3).sum())/10)\n",
    "        \n",
    "        \n",
    "        # print(Q_values)\n",
    "        # whittle_indexes[index][current_state[index]]+=beta*temp\n",
    "\n",
    "        # print(whittle_indexes)\n",
    "        # print(\"--\")\n",
    "        current_state[index]=new_state\n",
    "        reward_sum+=reward\n",
    "\n",
    "        #print(x)\n",
    "  # print(i)\n",
    "  # print(whittle_indexes)\n",
    "  # print(current_state[index])\n",
    "  # print(Q_values[index][current_state[index]][1])\n",
    "  # print(Q_values[index][current_state[index]][0])\n",
    "  # print((Q_values[index][current_state[index]][1]-Q_values[index][current_state[index]][0]))\n",
    "  # print('----')\n",
    "  # whittle_indexes=whittle_indexes_update(whittle_indexes,Q_values,beta,arm_indexes,state_space,T)\n",
    "  # print(w5)\n",
    "  # clear_output()\n",
    "\n",
    "  w1=w1+beta*(Q1[0][1]-Q1[0][0])\n",
    "  w2=w2+beta*(Q2[1][1]-Q2[1][0])\n",
    "  w3=w3+beta*(Q3[2][1]-Q3[2][0])\n",
    "  \n",
    "  # whittle_indexes_over_time.append(copy.deepcopy(whittle_indexes))\n",
    "  w_overtime.append([w1,w2,w3])\n",
    "  # epsilon=epsilon*gamma\n",
    "  if epsilon<=0.1:\n",
    "    epsilon=0.1\n",
    "  rewards.append(reward_sum)\n",
    "  action_sums.append(action_sum)\n",
    "  betas.append(beta)\n",
    "  alphas.append(alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=10000000\n",
    "j=0\n",
    "state1=[w_overtime[i][0] for i in range(t)]\n",
    "state2=[w_overtime[i][1] for i in range(t)]\n",
    "state3=[w_overtime[i][2] for i in range(t)]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(state1,color='r',label='state 1')\n",
    "plt.plot(state2,color='g',label='state 2')\n",
    "plt.plot(state3,color='b',label='state 3')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Whittle Index')\n",
    "plt.xlabel('steps')\n",
    "plt.ylim([-2,2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
